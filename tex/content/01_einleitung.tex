\chapter{Einleitung} \label{chap:einleitung}
Reinforcement Learning als maschinelles Lernverfahren ermöglicht eine vielversprechende Herangehensweise an die Entwicklung autonomer Systeme.
Es unterscheidet sich zu anderen maschinellen Lernverfahren, indem keine Kenntnis über die Klassenzugehörigkeit der Daten benötigt wird.
Insbesondere für die Anwendung in autonomen Systemen ist es z.B. bei überwachten Lernverfahren aufwendig, genügend große Datenmengen zu erzeugen, speziell dann, wenn alle Anwendungsfälle abgedeckt und eindeutig einer Klasse zugewiesen werden müssen.
Im Vergleich zu herkömmlichen Paradigmen bietet Reinforcement Learning die Möglichkeit zur selbständigen Anpassung und Generalisierung an fremde Situationen. 
Durch diese Potenzial besteht wirtschaftliches und politisches Interesse am Fortschritt, weshalb es umso wichtiger ist, eine sachliche Diskussion bezüglich der Nutzung und möglicher Bedenken zu führen.
Ein verantwortungsvoller Umgang bietet dann Potenzial für wirtschaftlichen und gesellschaftlichen Fortschritt.
Denn auch wenn die technischen Möglichkeiten vielversprechend aussehen, müssen bei allen lernenden Systemen neben ethischen Bedenken des Nutzungskontextes auch Bedenken während des Entwicklungsprozesses betrachtet werden, denn Fehlentscheidungen können fatale Folgen \cite{amodei2016}\cite{hawkins} haben und so das Wohl und die Würde des Menschen gefährden.
Es stellen sich deshalb die Fragen, welche Maßnahmen ergriffen werden können, damit Agenten zu unserem Wohl gemäß unserer Werte handeln, wie diese Werte formalisiert werden können und wie Adaption und Akzeptanz innerhalb der Gesellschaft zugesichert werden kann.
\ab 
Im Rahmen dieser Arbeit soll ein Vorgehensplan zur Umsetzung technischer und organisatorischer Maßnahmen erstellt werden, um ethisches Bedenken in bestehende Prozesse der Entwicklung von Reinforcement-Learning-Anwendungen zu integrieren.
Dafür werden zunächst Grundlagen des Reinforcement Learning als Kerntechnologie dieser Arbeit eingeführt.
Um nicht von einer einzelnen Technologie abhängig zu sein wird dafür der Markov-Entscheidungsprozess als Grundlage zur Umgebungsmodellierung, sowie allgemeine Begriffe und Eigenschaften eingeführt, wodurch eine eigene Evaluation der Technologie gemäß des Nutzungskontexts erfolgen kann.
Da im Rahmen der Arbeit Werte zum moralischen Handeln von Reinforcement-Learning-Agenten definiert und technische Maßnahmen zur Umsetzung dieser Werte aufgezeigt werden, wird anschließend ein Überblick über Grundlagen der angewandten Ethik und Moral, sowie der Maschinenethik als Bereichsethik gegeben und diskutiert, inwiefern Reinforcement-Learning-Agenten moralisch handeln können.
Anschließend werden als Grundlage der Definition der ethischen Werte die Maßnahmen zur Zusicherung ethischen Umgangs mit Künstlicher Intelligenz auf internationaler, europäischer und asiatischer Ebene, und der USA betrachtet. 
In \autoref{chap:diskussion} wird dann zunächst der Kontext der Arbeit abgegrenzt, Anwendungsgebiete sowie der Stand der Technik betrachtet und mit dieser Arbeit verglichen, sowie Herausforderungen bei der Konzeption technischer Maßnahmen ethischer Reinforcement-Learning-Anwendungen als Evaluationsgrundlage diskutiert.
In der eigentlichen Konzeption in \autoref{chap:konzeption} wird zunächst die Wahl ethischer Werte als Grundlage für die Erstellung des Vorgehensplan basierend auf den ethischen Grundlagen und der regionalen Maßnahmen begründet.
Anschließend wird in \autoref{sec:massnahmen} der eigentliche Vorgehensplan vorgestellt. 
Der Vorgehensplan ist angelehnt an einen generischen Softwareentwicklungszyklus \cite[S. 64]{broy2013}, zeigt technische und organisatorische Maßnahmen zur Umsetzung der ethischen Werte auf und beschreibt Möglichkeiten die in \autoref{sec:Herausforderungen} genannten Herausforderungen zu lösen.
Abschließend wird der Vorgehensplan gemäß der definierten Fragestellungen, den regionalen Maßnahmen der Länder und den Herausforderungen evaluiert, sowie abschließend zusammengefasst und ein Ausblick über mögliche zukünftige Weiterentwicklungen diskutiert.