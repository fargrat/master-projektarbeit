\section{Abgrenzung}\label{sec:abgrenzung}
Wenn die Rede von einem autonomen System ist, so wird im Kontext dieser Arbeit insbesondere ein Reinforcement Learning gestütztes System betrachtet.
Da Reinforcement-Learning-Systeme allerdings Überschneidungen mit anderen KI-Systemen aufweisen, sind die Aussagen teilweise auch auf diese übertragbar.
Die Kernproblematik ist meist ähnlich, unterscheidet sich allerdings insbesondere durch die Lösungsansätze.
Ziel der Arbeit ist die technischen Konzeption von ethischen Werten für Reinforcement-Learning-Anwendungen.
Zu beachten ist dabei, dass der technische Ansatz im Rahmen dieser Arbeit nur ein Mittel ist, um die ethischen Werte umzusetzen.
Nicht beachtet werden explizit technische Eigenschaften, wie beispielsweise Integrität, Interoperabilität oder Wartbarkeit, auch wenn diese möglicherweise implizit durch die Zusicherung der ethischen Werte abgedeckt werden.
\ab 
Das Oberthema der künstlichen Intelligenz ist sehr umfangreich, weswegen eine inhaltliche Abgrenzung sinnvoll ist.
Zunächst wird als Technologie ausschließlich Reinforcement Learning betrachtet. 
Die im Rahmen der Arbeit betrachteten Agenten sind beschränkt auf die Interaktion mit der Umwelt.
Eine Interaktion mit anderen Agenten in einer Multiagentenumgebung wird nicht betrachtet.
Ebenso werden starke, also domänenübergreifende oder selbstverbessernde Agenten nicht betrachtet, da es zum Zeitpunkt der Arbeit im Rahmen der Recherche neben \cite{hall2007} keine aktuellen Belege für den praktische Einsatz bzw. die Möglichkeit zur Nutzung gibt.
Inhaltlich werden sowohl Reinforcement-Learning-Agenten in Form von Expertensystemen mit indirektem Einfluss, wie auch Agenten mit direktem Einfluss in Form von Robotern o.Ä. betrachtet, da beide Agententypen Anwendung finden und eine enge inhaltliche Nähe aufweisen.
In \autoref{sec:stand_der_technik} werden teilweise andere Arbeiten aufgezeigt, die abgegrenzte Themen behandeln.